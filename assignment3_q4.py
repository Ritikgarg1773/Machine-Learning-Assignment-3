# -*- coding: utf-8 -*-
"""Assignment3_Q4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10qWZrb8SorD5qCru95nOtGkQeic4LrR7

Source: https://github.com/surabhisnath/Neural-Network-Implementation/blob/master/Assignment3_2016271_Alexnet_SVM.ipynb
        Sklearn Documentation
"""

from google.colab import drive
drive.mount('/content/gdrive')

import torch
import torch.nn as nn
import torchvision.models as models
import pickle
import numpy
from torch.autograd import Variable
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import normalize
import torchvision.transforms as transforms
from PIL import Image
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt
import numpy as np
#Source:

alexnet = models.alexnet(pretrained = True)
with open('/content/drive/MyDrive/Dataset/train_CIFAR.pickle', 'rb') as f: 
    data_train = pickle.load(f)
with open('/content/drive/MyDrive/Dataset/test_CIFAR.pickle', 'rb') as f: 
    data_test = pickle.load(f)

images = data_train['X']
labels = data_train['Y']
test_images = data_test['X']
test_labels = data_test['Y']

"""EDA analysis"""

import pandas as pd
df_X = pd.DataFrame(images)
df_y = labels
"""EDA Analysis of the given data"""
#Class distribution of every class and images of every class and image pixel value
print(df_X.shape, "shape")

print(df_X.head(), "head of X")
print(df_y[:10],"head of y")
print(df_X.columns, "columns of X")
# print(df_y.columns, "columns of y")
print(df_X.shape[0]," Number of samples")
print(np.max(images)," Maximum pixel value")
print(np.min(images), " Minimum pixel value")
print(np.mean(images.mean(axis=0)),"Mean pixel value")
print(np.unique(df_y,return_counts=True), " Class distribution ")

num_images = len(images)
num_test_images = len(test_images)
images_reshaped = images.reshape((num_images,3,32,32))
test_images_reshaped = test_images.reshape((num_test_images,3,32,32))

images_EDA = images[:10]
rows = int(np.sqrt(len(images_EDA)))
columns = int(np.sqrt(len(images_EDA)))
fig = plt.figure(figsize = (10, 10))
for i in range(rows*columns):
    ax = fig.add_subplot(rows, columns, i+1)
    image = images_EDA[i]
    ax.imshow(image.reshape(32,32,3))
    ax.axis('off')

conv = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])

features_train = []
for i in range(len(images)):
    pilimg_train = Image.fromarray(numpy.array(images_reshaped[i].T))
    fc_out = alexnet(conv(pilimg_train).unsqueeze(0))
    feature = numpy.squeeze(fc_out).tolist()    #remove the one-d elements using np.squeeze
    features_train.append(feature)   #append the fc8 feature in feature_train

test_features = []
for i in range(num_test_images):
    pilimg_test = Image.fromarray(numpy.array(test_images_reshaped[i].T))
    fc_out = alexnet(conv(pilimg_test).unsqueeze(0))
    #feature = fc_out.detach().numpy()
    #feature = numpy.squeeze(feature)
    feature = numpy.squeeze(fc_out).tolist()
    test_features.append(feature)

features_train = normalize(features_train)
print(features_train.shape)

test_features = normalize(test_features)
print(test_features.shape)

# f = open('test_features.pkl', 'wb')
# pickle.dump(test_features, f)
# f.close()

x_train = features_train       #taking the fc8 features and will pass them to neural network
y_train = labels
x_test = test_features
y_test = test_labels

#train the model using NN
from sklearn.neural_network import MLPClassifier
clf = MLPClassifier(hidden_layer_sizes=(512,256)).fit(x_train, y_train)

predictions = clf.predict(x_test)
print(accuracy_score(predictions, y_test))

#print the confusion matrix
confusion_matrix(predictions, y_test)

#print the ROC curve
probas = clf.predict_proba(x_test)
auc = roc_auc_score(y_test, probas[:,1])
fpr, tpr, thresholds = roc_curve(y_test, probas[:,1])
print(auc)

plt.plot(fpr, tpr, color='orange',
         lw = 2, label = 'ROC curve')
plt.plot([0, 1], [0, 1], color='red', lw = 2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
# plt.title('Receiver operating characteristic')
plt.legend()
plt.show()